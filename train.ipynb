{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP7MfUXlLqoA2UgjY1g7TAX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richmondvan/melanoma-detection/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GBnQEFeOgSK",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZUfw13gOyhU",
        "colab_type": "text"
      },
      "source": [
        "Import all modules and mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kAzzn_kNT3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Must be run every time!\n",
        "import pathlib\n",
        "import math\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import drive \n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import tensorflow as tf #nightly\n",
        "from tensorflow.keras import models, layers, losses, metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ayc9vJ-Ms1r",
        "colab_type": "text"
      },
      "source": [
        "Copy dataset to local drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Emd7mrlsLb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cp -R /content/gdrive/My Drive/Dataset/DatasetSorted /Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzfDku_bO18a",
        "colab_type": "text"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqBjcCuNjMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/Dataset/DatasetSorted/\"\n",
        "\n",
        "TRAINING_PATH = pathlib.Path(PATH + \"training/\")\n",
        "VALIDATION_PATH = pathlib.Path(PATH + \"validation/\")\n",
        "TEST_PATH = pathlib.Path(PATH + \"test/\")\n",
        "\n",
        "\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=(0.95, 1.05),\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True) # Generator for our validation data\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 600\n",
        "IMG_WIDTH = 600\n",
        "\n",
        "TRAIN_LEN = len(list(TRAINING_PATH.glob(\"*/*.jpg\")))\n",
        "VALID_LEN = len(list(VALIDATION_PATH.glob(\"*/*.jpg\")))\n",
        "\n",
        "print(TRAIN_LEN)\n",
        "print(VALID_LEN)\n",
        "\n",
        "CLASS_NAMES = ['benign', 'malignant']\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=TRAINING_PATH,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary',\n",
        "                                                           classes=CLASS_NAMES)\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=VALIDATION_PATH,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary',\n",
        "                                                              classes=CLASS_NAMES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U--YerHEO7gD",
        "colab_type": "text"
      },
      "source": [
        "Prepare metrics and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9iRPtTtNmHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numBenign = len(list(TRAINING_PATH.glob(\"benign/*.jpg\")))\n",
        "numMalignant = len(list(TRAINING_PATH.glob(\"malignant/*.jpg\")))\n",
        "total = numBenign + numMalignant\n",
        "weight_for_0 = (1 / numBenign)*(total)/2.0 \n",
        "weight_for_1 = (1.5 / numMalignant)*(total)/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1\n",
        "\n",
        "\n",
        "METRICS = [\n",
        "      metrics.TruePositives(name='tp'),\n",
        "      metrics.FalsePositives(name='fp'),\n",
        "      metrics.TrueNegatives(name='tn'),\n",
        "      metrics.FalseNegatives(name='fn'), \n",
        "      metrics.BinaryAccuracy(name='accuracy'),\n",
        "      metrics.Precision(name='precision'),\n",
        "      metrics.Recall(name='recall'),\n",
        "      metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmZ-5AzPZxU",
        "colab_type": "text"
      },
      "source": [
        "Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFVGzhJeNrat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NEURONS_PER_LAYER = 1024\n",
        "\n",
        "model = models.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/efficientnet/b7/feature-vector/1\", trainable=False),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(0.001), activation=\"relu\"),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=METRICS)\n",
        "\n",
        "model.build([None, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4lfi_UpPcDj",
        "colab_type": "text"
      },
      "source": [
        "Load model weights and last epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wVuJBRAEGbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCH_FILEPATH = f\"/content/gdrive/My Drive/Dataset/enet{NEURONS_PER_LAYER}_4_epochnum\"\n",
        "infile = open(EPOCH_FILEPATH, 'rb')\n",
        "try: \n",
        "    epoch = pickle.load(infile)\n",
        "    model.load_weights(f\"/content/gdrive/My Drive/Dataset/enet{NEURONS_PER_LAYER}_4_epoch{epoch}.h5\")\n",
        "except: \n",
        "    epoch = 0\n",
        "\n",
        "\n",
        "infile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftn4Tb_LM2d1",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1bTVD9HNsvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(epoch, 150):\n",
        "    outfile = open(EPOCH_FILEPATH, 'wb')\n",
        "    history = model.fit(x=train_data_gen, \n",
        "                        epochs=i+1, \n",
        "                        initial_epoch=i, \n",
        "                        verbose=1, \n",
        "                        validation_data=val_data_gen, \n",
        "                        validation_steps=VALID_LEN // batch_size, \n",
        "                        steps_per_epoch=TRAIN_LEN // batch_size, \n",
        "                        class_weight=class_weight)\n",
        "    model.save_weights(f\"/content/gdrive/My Drive/Dataset/enet{NEURONS_PER_LAYER}_4/epoch{i + 1}.h5\")\n",
        "    pickle.dump(i+1, outfile)\n",
        "    outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}