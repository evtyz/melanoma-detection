{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM0DpiZbwd80EA70RqqvP4T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richmondvan/melanoma-detection/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GBnQEFeOgSK",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZUfw13gOyhU",
        "colab_type": "text"
      },
      "source": [
        "Import all modules and mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kAzzn_kNT3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Must be run every time!\n",
        "\n",
        "from pathlib import Path # Manage file paths\n",
        "import pickle # Storing epoch number\n",
        "from google.colab import drive # For mounting GDrive\n",
        "import matplotlib.pyplot as plt # For data preview\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# tensorflow imports\n",
        "from tensorflow.keras import metrics, regularizers, models # utilities\n",
        "from tensorflow.keras.optimizers import Adam # optimizer\n",
        "from tensorflow.keras.losses import BinaryCrossentropy # loss function\n",
        "from tensorflow.keras.applications import MobileNetV2 # base model for transfer learning\n",
        "from tensorflow.keras.models import Sequential # model architecture\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D # additional layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # Data pipeline\n",
        "from tensorflow.keras.callbacks import CSVLogger # CSV logger callback\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive') # Mount the google drive where previous weights are stored\n",
        "\n",
        "!git clone https://github.com/richmondvan/isic-image-database.git # clone the dataset from Github"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzfDku_bO18a",
        "colab_type": "text"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqBjcCuNjMG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting up file paths\n",
        "PATH = \"/content/isic-image-database/\"\n",
        "\n",
        "# Filepaths for each of the datasets\n",
        "TRAINING_PATH = Path(PATH + \"training/\")\n",
        "VALIDATION_PATH = Path(PATH + \"validation/\")\n",
        "TEST_PATH = Path(PATH + \"test/\")\n",
        "\n",
        "# Create image generators for training data\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255, # Convert RGB values into floats between 0 and 1\n",
        "    brightness_range=(0.90, 1.10), # For data augmentation: Increase or decrease brightness by at most 10%.\n",
        "    zoom_range=[0.9, 1], # For data augmentation: Zoom in by at most 10%. No zooming out.\n",
        "    horizontal_flip=True, # For data augmentation: Flip along horizontal axis.\n",
        "    vertical_flip=True) # For data augmentation: Flip along vertical axis. \n",
        "\n",
        "# Create image generators for validation data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # No data augmentation, validation dataset must remain consistent.\n",
        "\n",
        "# Some constants\n",
        "BATCH_SIZE = 32 # Small batch size for good generalization\n",
        "\n",
        "# Image is a square, 224x224.\n",
        "IMG_HEIGHT = 224 \n",
        "IMG_WIDTH = IMG_HEIGHT \n",
        "\n",
        "# Get size of data generators, by globbing based on file extension .jpg\n",
        "TRAIN_LEN = len(list(TRAINING_PATH.glob(\"*/*.jpg\")))\n",
        "VALID_LEN = len(list(VALIDATION_PATH.glob(\"*/*.jpg\")))\n",
        "\n",
        "# Hardcoded directory names to sort classes from.\n",
        "CLASS_NAMES = ['benign', 'malignant']\n",
        "\n",
        "# Get generated datasets\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=TRAINING_PATH,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary',\n",
        "                                                           classes=CLASS_NAMES)\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=VALIDATION_PATH,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary',\n",
        "                                                              classes=CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPIAgll7WrNF",
        "colab_type": "text"
      },
      "source": [
        "Show images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKy36frtVTTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_batch, label_batch = next(train_data_gen)\n",
        "\n",
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(25):\n",
        "      ax = plt.subplot(5,5,n+1)\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
        "      plt.axis('off')\n",
        "\n",
        "show_batch(image_batch, label_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U--YerHEO7gD",
        "colab_type": "text"
      },
      "source": [
        "Prepare metrics and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9iRPtTtNmHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get some training weights to offset class imbalance\n",
        "numBenign = len(list(TRAINING_PATH.glob(\"benign/*.jpg\")))\n",
        "numMalignant = len(list(TRAINING_PATH.glob(\"malignant/*.jpg\")))\n",
        "total = numBenign + numMalignant\n",
        "\n",
        "# Depending on how we value precision and recall, this may change in the future...\n",
        "ADDITIONAL_WEIGHT_MULTIPLIER = 1.0\n",
        "\n",
        "# Weights for learning. Malignant cases are weighted more heavily, to offset imbalanced datasets.\n",
        "weight_for_0 = (1 / numBenign) * (total) / 2.0 \n",
        "weight_for_1 = (ADDITIONAL_WEIGHT_MULTIPLIER / numMalignant) * (total) / 2.0\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "# Check the weight.\n",
        "print(class_weight)\n",
        "\n",
        "# Metrics we will be using to assess accuracy\n",
        "METRICS = [\n",
        "      metrics.BinaryAccuracy(name='acc'), # Raw accuracy.\n",
        "      metrics.TruePositives(name='tp'),\n",
        "      metrics.FalsePositives(name='fp'),\n",
        "      metrics.TrueNegatives(name='tn'),\n",
        "      metrics.FalseNegatives(name='fn'), \n",
        "      metrics.Precision(name='pre'), # tp / (tp + fp)\n",
        "      metrics.Recall(name='rec'), # tp / (tp + fn)\n",
        "      metrics.AUC(name='auc'), # area under curve\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmZ-5AzPZxU",
        "colab_type": "text"
      },
      "source": [
        "Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFVGzhJeNrat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "REG_LAMBDA = 0.001 # coefficient for regularization\n",
        "DROPOUT = 0.1 # 10% dropout per layer\n",
        "ACTIVATION = \"relu\"\n",
        "NEURONS_PER_LAYER = 512\n",
        "NUM_DENSE_LAYERS = 8\n",
        "\n",
        "# The image shape has three channels, so it is 224x224x3.\n",
        "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
        "\n",
        "# Get the base model for transfer learning, but remove the classification head. Freeze.\n",
        "base_model = MobileNetV2(input_shape = IMG_SHAPE, include_top=False, weights='imagenet', alpha=1.4, pooling='avg')\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the full Sequential model.\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "# Add a base dropout\n",
        "model.add(Dropout(DROPOUT))\n",
        "# Add some dense layers.\n",
        "for x in range(NUM_DENSE_LAYERS):\n",
        "    model.add(Dense(NEURONS_PER_LAYER, kernel_regularizer=regularizers.l2(REG_LAMBDA), activation=ACTIVATION))\n",
        "    model.add(Dropout(DROPOUT))\n",
        "# Add a classification head.\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# Small learning rate.\n",
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "def compileModel(learningRate):\n",
        "    global model\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learningRate),\n",
        "        loss=BinaryCrossentropy(from_logits=True),\n",
        "        metrics=METRICS)\n",
        "\n",
        "compileModel(LEARNING_RATE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4lfi_UpPcDj",
        "colab_type": "text"
      },
      "source": [
        "Load model weights and last epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wVuJBRAEGbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get last epoch number from pickled file\n",
        "\n",
        "MODEL_FILEPATH = f\"/content/gdrive/My Drive/MelanomaDetectionModels/{NEURONS_PER_LAYER}_{NUM_DENSE_LAYERS}/\"\n",
        "EPOCH_FILEPATH = MODEL_FILEPATH + \"epochnum.pkl\"\n",
        "\n",
        "# Loads weights.\n",
        "def loadWeights():\n",
        "    global epoch, model, EPOCH_FILEPATH, MODEL_FILEPATH\n",
        "    try: \n",
        "        infile = open(EPOCH_FILEPATH, 'rb')\n",
        "        infile.seek(0)\n",
        "        epoch = pickle.load(infile)\n",
        "        try:\n",
        "            model.load_weights(MODEL_FILEPATH + f\"epoch{epoch}.h5\")\n",
        "            infile.close()\n",
        "        except:\n",
        "            pass\n",
        "    except: \n",
        "        # Otherwise start again (only happens if no epoch number found)\n",
        "        epoch = 0\n",
        "    print(epoch)\n",
        "\n",
        "loadWeights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIC8UGzFk7AJ",
        "colab_type": "text"
      },
      "source": [
        "Prepare CSV logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLyBNCPteyrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File where we store our CSV history\n",
        "\n",
        "HISTORY_FILEPATH = MODEL_FILEPATH + \"history.csv\"\n",
        "\n",
        "csv_logger = CSVLogger(HISTORY_FILEPATH, append=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftn4Tb_LM2d1",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1bTVD9HNsvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train for 150 epochs\n",
        "\n",
        "epochsToTrain = 150\n",
        "\n",
        "def trainModel(epochsToFit): # Trains the model up to a specified epoch number\n",
        "    global epoch, model, train_data_gen, val_data_gen, VALID_LEN, TRAIN_LEN, BATCH_SIZE, class_weight, csv_logger, MODEL_FILEPATH, EPOCH_FILEPATH\n",
        "    if epoch < epochsToFit:\n",
        "        for i in range(epoch, epochsToFit):\n",
        "            # Train the model, one epoch at a time.\n",
        "            history = model.fit(x=train_data_gen, # training data\n",
        "                                epochs=i+1, # epoch to train to (next epoch)\n",
        "                                initial_epoch=i, # current epoch\n",
        "                                verbose=1, # show progress\n",
        "                                validation_data=val_data_gen, # validation data \n",
        "                                validation_steps=VALID_LEN // BATCH_SIZE, # validation batch steps\n",
        "                                steps_per_epoch=TRAIN_LEN // BATCH_SIZE, # training batch steps\n",
        "                                class_weight=class_weight, # class weights (to avoid imbalanced training)\n",
        "                                callbacks = [csv_logger]) # CSV logger callback\n",
        "            model.save_weights(MODEL_FILEPATH + f\"epoch{i + 1}.h5\") # save the new epoch weights for records later.\n",
        "            outfile = open(EPOCH_FILEPATH, 'wb') # dump the current epoch (in case Colab decides to stop before the loop finishes.)\n",
        "            pickle.dump(i+1, outfile)\n",
        "            outfile.close()\n",
        "\n",
        "trainModel(epochsToTrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-bRTiM3aPyw",
        "colab_type": "text"
      },
      "source": [
        "Fine-Tune training, on a step-wise basis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaWGzoWEXOdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_MODEL_SIZE = len(base_model.layers) # Number of layers in MobileNetV2 (should be 156)\n",
        "EPOCHS_FOR_FINE_TUNE = 100 # Epochs to fine-tune for at each stage.\n",
        "\n",
        "CURRENT_CYCLE = 1 # Default cycle number\n",
        "\n",
        "NUM_LAYERS_TO_FINE_TUNE = 25 # Number of layers that are fine-tuned at once.\n",
        "\n",
        "if epoch >= epochsToTrain:\n",
        "    loadWeights() # Load weights (to update epoch num)\n",
        "    CURRENT_CYCLE = 1 + int((epoch - epochsToTrain) / EPOCHS_FOR_FINE_TUNE) # calculate current cycle from weights by rounding down quotient.\n",
        "\n",
        "FINE_TUNE_CYCLES = 2 # Total number of cycles\n",
        "\n",
        "print(CURRENT_CYCLE)\n",
        "\n",
        "regularizer = regularizers.l2(REG_LAMBDA) # Regularization for fine-tuning\n",
        "\n",
        "for cycleIndex in range(CURRENT_CYCLE, FINE_TUNE_CYCLES + 1): # loops through all steps of fine-tuning from current to total.\n",
        "    fine_tune_from = BASE_MODEL_SIZE - 1 - (NUM_LAYERS_TO_FINE_TUNE * cycleIndex) # Calculates which layer fine-tuning begins, minus one for the pooling layer.\n",
        "    base_model.trainable = False # Set everything to untrainable at first...\n",
        "    for layer in base_model.layers[fine_tune_from:]: # and then set all layers after fine_tune_from to be trainable.\n",
        "        layer.trainable = True    \n",
        "        for attr in ['kernel_regularizer']:\n",
        "            if hasattr(layer, attr):\n",
        "                setattr(layer, attr, regularizer)\n",
        "    # When we change the layers attributes, the change only happens in the model config file\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    # Save the weights before reloading the model.\n",
        "    tmp_weights_path = os.path.join(tempfile.gettempdir(), 'tmp_weights.h5')\n",
        "    model.save_weights(tmp_weights_path)\n",
        "\n",
        "    # load the model from the config\n",
        "    model = models.model_from_json(model_json)\n",
        "    \n",
        "    # Reload the model weights\n",
        "    model.load_weights(tmp_weights_path, by_name=True)\n",
        "\n",
        "    compileModel(LEARNING_RATE/10) # compile the new model with a reduced learning-rate\n",
        "    model.summary() # show the model\n",
        "    trainModel(epochsToTrain + EPOCHS_FOR_FINE_TUNE * cycleIndex) # train it up to the new epoch\n",
        "    loadWeights() # load new epoch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iyUrm2zKK9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset epochnum\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# MODEL_FILEPATH = f\"/content/gdrive/My Drive/MelanomaDetectionModels/512_8/\"\n",
        "# EPOCH_FILEPATH = MODEL_FILEPATH + \"epochnum.pkl\"\n",
        "# outfile = open(EPOCH_FILEPATH, 'wb') # dump the current epoch (in case Colab decides to stop before the loop finishes.)\n",
        "# pickle.dump(150, outfile)\n",
        "# outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}