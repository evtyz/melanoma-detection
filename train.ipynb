{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMytuJd2GWnyDZMUmlD1xYB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richmondvan/melanoma-detection/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GBnQEFeOgSK",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZUfw13gOyhU",
        "colab_type": "text"
      },
      "source": [
        "Import all modules and mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kAzzn_kNT3v",
        "colab_type": "code",
        "outputId": "020ccdb4-6be6-471e-d57f-2c913eeec2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Must be run every time!\n",
        "\n",
        "import pathlib # Manage file paths\n",
        "import math # Manage basic math\n",
        "import pickle # Storing epoch number\n",
        "import csv # Storing data in .csv files\n",
        "from google.colab import drive # For mounting GDrive\n",
        "import tensorflow_hub as hub # For importing EfficientNet\n",
        "\n",
        "import tensorflow as tf #nightly\n",
        "from tensorflow.keras import models, layers, losses, metrics\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive') "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzfDku_bO18a",
        "colab_type": "text"
      },
      "source": [
        "Prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqBjcCuNjMG",
        "colab_type": "code",
        "outputId": "1df59c44-bc95-4e89-8fb2-84c05281c3de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Setting up file paths\n",
        "PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/\"\n",
        "\n",
        "TRAINING_PATH = pathlib.Path(PATH + \"training/\")\n",
        "VALIDATION_PATH = pathlib.Path(PATH + \"validation/\")\n",
        "TEST_PATH = pathlib.Path(PATH + \"test/\")\n",
        "\n",
        "# Create image generators\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    brightness_range=(0.95, 1.05),\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True) # Generator for our validation data\n",
        "\n",
        "# Some constants\n",
        "batch_size = 32\n",
        "IMG_HEIGHT = 380\n",
        "IMG_WIDTH = 380\n",
        "TRAIN_LEN = len(list(TRAINING_PATH.glob(\"*/*.jpg\")))\n",
        "VALID_LEN = len(list(VALIDATION_PATH.glob(\"*/*.jpg\")))\n",
        "CLASS_NAMES = ['benign', 'malignant']\n",
        "\n",
        "# Get generated datasets\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=TRAINING_PATH,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary',\n",
        "                                                           classes=CLASS_NAMES)\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=VALIDATION_PATH,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary',\n",
        "                                                              classes=CLASS_NAMES)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8423 images belonging to 2 classes.\n",
            "Found 1054 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U--YerHEO7gD",
        "colab_type": "text"
      },
      "source": [
        "Prepare metrics and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9iRPtTtNmHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get some training weights to offset class imbalance\n",
        "numBenign = len(list(TRAINING_PATH.glob(\"benign/*.jpg\")))\n",
        "numMalignant = len(list(TRAINING_PATH.glob(\"malignant/*.jpg\")))\n",
        "total = numBenign + numMalignant\n",
        "\n",
        "additionalWeightMultiplier = 1.5\n",
        "\n",
        "weight_for_0 = (1 / numBenign) * (total) / 2.0 \n",
        "weight_for_1 = (additionalWeightMultiplier / numMalignant) * (total) / 2.0\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "# Metrics we will be using to assess accuracy\n",
        "METRICS = [\n",
        "      metrics.BinaryAccuracy(name='accuracy'),\n",
        "      metrics.TruePositives(name='tp'),\n",
        "      metrics.FalsePositives(name='fp'),\n",
        "      metrics.TrueNegatives(name='tn'),\n",
        "      metrics.FalseNegatives(name='fn'), \n",
        "      metrics.Precision(name='precision'),\n",
        "      metrics.Recall(name='recall'),\n",
        "      metrics.AUC(name='auc'),\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnmZ-5AzPZxU",
        "colab_type": "text"
      },
      "source": [
        "Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFVGzhJeNrat",
        "colab_type": "code",
        "outputId": "d8e0711b-e5dc-4212-b802-7d82a8acbd52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# Hyperparameters\n",
        "NEURONS_PER_LAYER = 256\n",
        "REG_LAMBDA = 0.001\n",
        "DROPOUT = 0.1\n",
        "ACTIVATION = \"relu\"\n",
        "\n",
        "# Build model\n",
        "model = models.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/lite4/feature-vector/2\", trainable=False),\n",
        "    layers.Dropout(DROPOUT),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "    layers.Dropout(DROPOUT),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "    layers.Dropout(DROPOUT),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "    layers.Dropout(DROPOUT),\n",
        "    layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "    layers.Dropout(DROPOUT),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=METRICS)\n",
        "\n",
        "model.build([None, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     multiple                  11837936  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  327936    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65792     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              multiple                  257       \n",
            "=================================================================\n",
            "Total params: 12,363,505\n",
            "Trainable params: 525,569\n",
            "Non-trainable params: 11,837,936\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4lfi_UpPcDj",
        "colab_type": "text"
      },
      "source": [
        "Load model weights and last epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wVuJBRAEGbh",
        "colab_type": "code",
        "outputId": "57d1ed2a-c923-4d36-861e-6ab894620951",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Get last epoch number from pickled file\n",
        "\n",
        "transferLearningCode = \"enetlite\"\n",
        "\n",
        "EPOCH_FILEPATH = f\"/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_4_epochnum\"\n",
        "\n",
        "try: \n",
        "    infile = open(EPOCH_FILEPATH, 'rb')\n",
        "    infile.seek(0)\n",
        "    epoch = pickle.load(infile)\n",
        "    model.load_weights(f\"/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_4/epoch{epoch}.h5\")\n",
        "    infile.close()\n",
        "except: \n",
        "    # Otherwise start again (only happens if no epoch number found)\n",
        "    epoch = 0\n",
        "\n",
        "\n",
        "print(epoch)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIC8UGzFk7AJ",
        "colab_type": "text"
      },
      "source": [
        "Prepare CSV logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLyBNCPteyrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File where we store our CSV history\n",
        "\n",
        "HISTORY_FILE = f'/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_stats.csv'\n",
        "\n",
        "csv_logger = CSVLogger(HISTORY_FILE, append=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftn4Tb_LM2d1",
        "colab_type": "text"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1bTVD9HNsvj",
        "colab_type": "code",
        "outputId": "667b60e2-692e-4b09-f19e-04700960e29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train for 50 epochs\n",
        "\n",
        "epochsToTrain = 100\n",
        "\n",
        "if epoch < epochsToTrain:\n",
        "    for i in range(epoch, epochsToTrain):\n",
        "        history = model.fit(x=train_data_gen, \n",
        "                            epochs=i+1, \n",
        "                            initial_epoch=i, \n",
        "                            verbose=1, \n",
        "                            validation_data=val_data_gen, \n",
        "                            validation_steps=VALID_LEN // batch_size, \n",
        "                            steps_per_epoch=TRAIN_LEN // batch_size, \n",
        "                            class_weight=class_weight,\n",
        "                            callbacks = [csv_logger])\n",
        "        model.save_weights(f\"/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_4/epoch{i + 1}.h5\")\n",
        "        outfile = open(EPOCH_FILEPATH, 'wb')\n",
        "        pickle.dump(i+1, outfile)\n",
        "        outfile.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/6\n",
            "263/263 [==============================] - 494s 2s/step - loss: 0.7661 - accuracy: 0.7172 - tp: 1003.0000 - fp: 2052.0000 - tn: 5033.0000 - fn: 328.0000 - precision: 0.3283 - recall: 0.7536 - auc: 0.7907 - val_loss: 0.8113 - val_accuracy: 0.7256 - val_tp: 136.0000 - val_fp: 255.0000 - val_tn: 607.0000 - val_fn: 26.0000 - val_precision: 0.3478 - val_recall: 0.8395 - val_auc: 0.8471\n",
            "Epoch 7/7\n",
            "263/263 [==============================] - 501s 2s/step - loss: 0.7572 - accuracy: 0.7311 - tp: 1010.0000 - fp: 1943.0000 - tn: 5143.0000 - fn: 320.0000 - precision: 0.3420 - recall: 0.7594 - auc: 0.8023 - val_loss: 0.7642 - val_accuracy: 0.7988 - val_tp: 112.0000 - val_fp: 156.0000 - val_tn: 706.0000 - val_fn: 50.0000 - val_precision: 0.4179 - val_recall: 0.6914 - val_auc: 0.8468\n",
            "Epoch 8/8\n",
            "263/263 [==============================] - 498s 2s/step - loss: 0.7518 - accuracy: 0.7303 - tp: 1041.0000 - fp: 1980.0000 - tn: 5105.0000 - fn: 290.0000 - precision: 0.3446 - recall: 0.7821 - auc: 0.8132 - val_loss: 0.7826 - val_accuracy: 0.7676 - val_tp: 123.0000 - val_fp: 195.0000 - val_tn: 663.0000 - val_fn: 43.0000 - val_precision: 0.3868 - val_recall: 0.7410 - val_auc: 0.8537\n",
            "Epoch 9/9\n",
            "263/263 [==============================] - 500s 2s/step - loss: 0.7515 - accuracy: 0.7477 - tp: 1001.0000 - fp: 1793.0000 - tn: 5292.0000 - fn: 330.0000 - precision: 0.3583 - recall: 0.7521 - auc: 0.8173 - val_loss: 0.8149 - val_accuracy: 0.7217 - val_tp: 138.0000 - val_fp: 259.0000 - val_tn: 601.0000 - val_fn: 26.0000 - val_precision: 0.3476 - val_recall: 0.8415 - val_auc: 0.8504\n",
            "Epoch 10/10\n",
            "263/263 [==============================] - 500s 2s/step - loss: 0.7535 - accuracy: 0.7423 - tp: 1012.0000 - fp: 1849.0000 - tn: 5235.0000 - fn: 320.0000 - precision: 0.3537 - recall: 0.7598 - auc: 0.8067 - val_loss: 0.7968 - val_accuracy: 0.7568 - val_tp: 130.0000 - val_fp: 218.0000 - val_tn: 645.0000 - val_fn: 31.0000 - val_precision: 0.3736 - val_recall: 0.8075 - val_auc: 0.8449\n",
            "Epoch 11/11\n",
            "263/263 [==============================] - 495s 2s/step - loss: 0.7536 - accuracy: 0.7029 - tp: 1077.0000 - fp: 2245.0000 - tn: 4839.0000 - fn: 255.0000 - precision: 0.3242 - recall: 0.8086 - auc: 0.8098 - val_loss: 0.8016 - val_accuracy: 0.7393 - val_tp: 138.0000 - val_fp: 240.0000 - val_tn: 619.0000 - val_fn: 27.0000 - val_precision: 0.3651 - val_recall: 0.8364 - val_auc: 0.8525\n",
            "Epoch 12/12\n",
            "263/263 [==============================] - 492s 2s/step - loss: 0.7469 - accuracy: 0.7389 - tp: 1043.0000 - fp: 1909.0000 - tn: 5176.0000 - fn: 288.0000 - precision: 0.3533 - recall: 0.7836 - auc: 0.8237 - val_loss: 0.7825 - val_accuracy: 0.7725 - val_tp: 125.0000 - val_fp: 195.0000 - val_tn: 666.0000 - val_fn: 38.0000 - val_precision: 0.3906 - val_recall: 0.7669 - val_auc: 0.8403\n",
            "Epoch 13/13\n",
            "263/263 [==============================] - 492s 2s/step - loss: 0.7492 - accuracy: 0.7563 - tp: 996.0000 - fp: 1717.0000 - tn: 5369.0000 - fn: 334.0000 - precision: 0.3671 - recall: 0.7489 - auc: 0.8120 - val_loss: 0.8033 - val_accuracy: 0.7559 - val_tp: 131.0000 - val_fp: 218.0000 - val_tn: 643.0000 - val_fn: 32.0000 - val_precision: 0.3754 - val_recall: 0.8037 - val_auc: 0.8517\n",
            "Epoch 14/14\n",
            "263/263 [==============================] - 497s 2s/step - loss: 0.7444 - accuracy: 0.7536 - tp: 1024.0000 - fp: 1767.0000 - tn: 5318.0000 - fn: 307.0000 - precision: 0.3669 - recall: 0.7693 - auc: 0.8221 - val_loss: 0.8965 - val_accuracy: 0.6123 - val_tp: 157.0000 - val_fp: 393.0000 - val_tn: 470.0000 - val_fn: 4.0000 - val_precision: 0.2855 - val_recall: 0.9752 - val_auc: 0.8243\n",
            "Epoch 15/15\n",
            "263/263 [==============================] - 497s 2s/step - loss: 0.7501 - accuracy: 0.7286 - tp: 1039.0000 - fp: 1993.0000 - tn: 5093.0000 - fn: 291.0000 - precision: 0.3427 - recall: 0.7812 - auc: 0.8069 - val_loss: 0.7725 - val_accuracy: 0.7891 - val_tp: 118.0000 - val_fp: 172.0000 - val_tn: 690.0000 - val_fn: 44.0000 - val_precision: 0.4069 - val_recall: 0.7284 - val_auc: 0.8479\n",
            "Epoch 16/16\n",
            "263/263 [==============================] - 496s 2s/step - loss: 0.7560 - accuracy: 0.7412 - tp: 988.0000 - fp: 1834.0000 - tn: 5250.0000 - fn: 344.0000 - precision: 0.3501 - recall: 0.7417 - auc: 0.8044 - val_loss: 0.7904 - val_accuracy: 0.7676 - val_tp: 138.0000 - val_fp: 210.0000 - val_tn: 648.0000 - val_fn: 28.0000 - val_precision: 0.3966 - val_recall: 0.8313 - val_auc: 0.8494\n",
            "Epoch 17/17\n",
            "263/263 [==============================] - 493s 2s/step - loss: 0.7470 - accuracy: 0.7241 - tp: 1077.0000 - fp: 2067.0000 - tn: 5017.0000 - fn: 255.0000 - precision: 0.3426 - recall: 0.8086 - auc: 0.8179 - val_loss: 0.7858 - val_accuracy: 0.7686 - val_tp: 122.0000 - val_fp: 200.0000 - val_tn: 665.0000 - val_fn: 37.0000 - val_precision: 0.3789 - val_recall: 0.7673 - val_auc: 0.8558\n",
            "Epoch 18/18\n",
            "263/263 [==============================] - 496s 2s/step - loss: 0.7466 - accuracy: 0.7294 - tp: 1070.0000 - fp: 2016.0000 - tn: 5069.0000 - fn: 261.0000 - precision: 0.3467 - recall: 0.8039 - auc: 0.8139 - val_loss: 0.8018 - val_accuracy: 0.7471 - val_tp: 134.0000 - val_fp: 232.0000 - val_tn: 631.0000 - val_fn: 27.0000 - val_precision: 0.3661 - val_recall: 0.8323 - val_auc: 0.8576\n",
            "Epoch 19/19\n",
            "263/263 [==============================] - 496s 2s/step - loss: 0.7457 - accuracy: 0.7306 - tp: 1062.0000 - fp: 1997.0000 - tn: 5087.0000 - fn: 270.0000 - precision: 0.3472 - recall: 0.7973 - auc: 0.8163 - val_loss: 0.8102 - val_accuracy: 0.7383 - val_tp: 141.0000 - val_fp: 247.0000 - val_tn: 615.0000 - val_fn: 21.0000 - val_precision: 0.3634 - val_recall: 0.8704 - val_auc: 0.8580\n",
            "Epoch 20/20\n",
            "263/263 [==============================] - 501s 2s/step - loss: 0.7430 - accuracy: 0.7429 - tp: 1056.0000 - fp: 1889.0000 - tn: 5196.0000 - fn: 275.0000 - precision: 0.3586 - recall: 0.7934 - auc: 0.8300 - val_loss: 0.7791 - val_accuracy: 0.7783 - val_tp: 122.0000 - val_fp: 187.0000 - val_tn: 675.0000 - val_fn: 40.0000 - val_precision: 0.3948 - val_recall: 0.7531 - val_auc: 0.8619\n",
            "Epoch 21/21\n",
            "263/263 [==============================] - 499s 2s/step - loss: 0.7386 - accuracy: 0.7462 - tp: 1071.0000 - fp: 1880.0000 - tn: 5209.0000 - fn: 256.0000 - precision: 0.3629 - recall: 0.8071 - auc: 0.8291 - val_loss: 0.7919 - val_accuracy: 0.7559 - val_tp: 119.0000 - val_fp: 206.0000 - val_tn: 655.0000 - val_fn: 44.0000 - val_precision: 0.3662 - val_recall: 0.7301 - val_auc: 0.8447\n",
            "Epoch 22/22\n",
            "263/263 [==============================] - 501s 2s/step - loss: 0.7474 - accuracy: 0.7588 - tp: 1001.0000 - fp: 1699.0000 - tn: 5385.0000 - fn: 331.0000 - precision: 0.3707 - recall: 0.7515 - auc: 0.8170 - val_loss: 0.7939 - val_accuracy: 0.7646 - val_tp: 135.0000 - val_fp: 213.0000 - val_tn: 648.0000 - val_fn: 28.0000 - val_precision: 0.3879 - val_recall: 0.8282 - val_auc: 0.8505\n",
            "Epoch 23/23\n",
            "263/263 [==============================] - 505s 2s/step - loss: 0.7498 - accuracy: 0.7306 - tp: 1040.0000 - fp: 1976.0000 - tn: 5109.0000 - fn: 291.0000 - precision: 0.3448 - recall: 0.7814 - auc: 0.8122 - val_loss: 0.8419 - val_accuracy: 0.6904 - val_tp: 143.0000 - val_fp: 300.0000 - val_tn: 564.0000 - val_fn: 17.0000 - val_precision: 0.3228 - val_recall: 0.8938 - val_auc: 0.8266\n",
            "Epoch 24/24\n",
            "263/263 [==============================] - 499s 2s/step - loss: 0.7416 - accuracy: 0.7458 - tp: 1068.0000 - fp: 1877.0000 - tn: 5209.0000 - fn: 262.0000 - precision: 0.3626 - recall: 0.8030 - auc: 0.8255 - val_loss: 0.8147 - val_accuracy: 0.7246 - val_tp: 139.0000 - val_fp: 258.0000 - val_tn: 603.0000 - val_fn: 24.0000 - val_precision: 0.3501 - val_recall: 0.8528 - val_auc: 0.8341\n",
            "Epoch 25/25\n",
            "263/263 [==============================] - 500s 2s/step - loss: 0.7419 - accuracy: 0.7652 - tp: 1002.0000 - fp: 1648.0000 - tn: 5438.0000 - fn: 328.0000 - precision: 0.3781 - recall: 0.7534 - auc: 0.8226 - val_loss: 0.7921 - val_accuracy: 0.7617 - val_tp: 131.0000 - val_fp: 212.0000 - val_tn: 649.0000 - val_fn: 32.0000 - val_precision: 0.3819 - val_recall: 0.8037 - val_auc: 0.8559\n",
            "Epoch 26/26\n",
            "263/263 [==============================] - 504s 2s/step - loss: 0.7424 - accuracy: 0.7445 - tp: 1062.0000 - fp: 1880.0000 - tn: 5204.0000 - fn: 270.0000 - precision: 0.3610 - recall: 0.7973 - auc: 0.8306 - val_loss: 0.7947 - val_accuracy: 0.7617 - val_tp: 130.0000 - val_fp: 212.0000 - val_tn: 650.0000 - val_fn: 32.0000 - val_precision: 0.3801 - val_recall: 0.8025 - val_auc: 0.8549\n",
            "Epoch 27/27\n",
            "263/263 [==============================] - 505s 2s/step - loss: 0.7417 - accuracy: 0.7508 - tp: 1038.0000 - fp: 1804.0000 - tn: 5281.0000 - fn: 293.0000 - precision: 0.3652 - recall: 0.7799 - auc: 0.8275 - val_loss: 0.7978 - val_accuracy: 0.7539 - val_tp: 132.0000 - val_fp: 222.0000 - val_tn: 640.0000 - val_fn: 30.0000 - val_precision: 0.3729 - val_recall: 0.8148 - val_auc: 0.8390\n",
            "Epoch 28/28\n",
            "263/263 [==============================] - 509s 2s/step - loss: 0.7412 - accuracy: 0.7608 - tp: 1028.0000 - fp: 1710.0000 - tn: 5375.0000 - fn: 303.0000 - precision: 0.3755 - recall: 0.7724 - auc: 0.8263 - val_loss: 0.7889 - val_accuracy: 0.7676 - val_tp: 128.0000 - val_fp: 203.0000 - val_tn: 658.0000 - val_fn: 35.0000 - val_precision: 0.3867 - val_recall: 0.7853 - val_auc: 0.8387\n",
            "Epoch 29/29\n",
            "263/263 [==============================] - 510s 2s/step - loss: 0.7382 - accuracy: 0.7634 - tp: 1035.0000 - fp: 1695.0000 - tn: 5390.0000 - fn: 296.0000 - precision: 0.3791 - recall: 0.7776 - auc: 0.8295 - val_loss: 0.7357 - val_accuracy: 0.8447 - val_tp: 99.0000 - val_fp: 95.0000 - val_tn: 766.0000 - val_fn: 64.0000 - val_precision: 0.5103 - val_recall: 0.6074 - val_auc: 0.8345\n",
            "Epoch 30/30\n",
            "263/263 [==============================] - 509s 2s/step - loss: 0.7400 - accuracy: 0.7507 - tp: 1061.0000 - fp: 1829.0000 - tn: 5257.0000 - fn: 269.0000 - precision: 0.3671 - recall: 0.7977 - auc: 0.8227 - val_loss: 0.7439 - val_accuracy: 0.8340 - val_tp: 109.0000 - val_fp: 115.0000 - val_tn: 745.0000 - val_fn: 55.0000 - val_precision: 0.4866 - val_recall: 0.6646 - val_auc: 0.8333\n",
            "Epoch 31/31\n",
            "263/263 [==============================] - 512s 2s/step - loss: 0.7395 - accuracy: 0.7596 - tp: 1045.0000 - fp: 1736.0000 - tn: 5348.0000 - fn: 287.0000 - precision: 0.3758 - recall: 0.7845 - auc: 0.8300 - val_loss: 0.8022 - val_accuracy: 0.7510 - val_tp: 131.0000 - val_fp: 228.0000 - val_tn: 638.0000 - val_fn: 27.0000 - val_precision: 0.3649 - val_recall: 0.8291 - val_auc: 0.8525\n",
            "Epoch 32/32\n",
            "263/263 [==============================] - 515s 2s/step - loss: 0.7373 - accuracy: 0.7672 - tp: 1038.0000 - fp: 1665.0000 - tn: 5419.0000 - fn: 294.0000 - precision: 0.3840 - recall: 0.7793 - auc: 0.8310 - val_loss: 0.7378 - val_accuracy: 0.8369 - val_tp: 96.0000 - val_fp: 100.0000 - val_tn: 761.0000 - val_fn: 67.0000 - val_precision: 0.4898 - val_recall: 0.5890 - val_auc: 0.8414\n",
            "Epoch 33/33\n",
            "263/263 [==============================] - 505s 2s/step - loss: 0.7387 - accuracy: 0.7647 - tp: 1041.0000 - fp: 1690.0000 - tn: 5395.0000 - fn: 290.0000 - precision: 0.3812 - recall: 0.7821 - auc: 0.8278 - val_loss: 0.7500 - val_accuracy: 0.8232 - val_tp: 106.0000 - val_fp: 126.0000 - val_tn: 737.0000 - val_fn: 55.0000 - val_precision: 0.4569 - val_recall: 0.6584 - val_auc: 0.8086\n",
            "Epoch 34/34\n",
            "263/263 [==============================] - 505s 2s/step - loss: 0.7402 - accuracy: 0.7621 - tp: 1032.0000 - fp: 1705.0000 - tn: 5382.0000 - fn: 297.0000 - precision: 0.3771 - recall: 0.7765 - auc: 0.8190 - val_loss: 0.7645 - val_accuracy: 0.8125 - val_tp: 120.0000 - val_fp: 152.0000 - val_tn: 712.0000 - val_fn: 40.0000 - val_precision: 0.4412 - val_recall: 0.7500 - val_auc: 0.8620\n",
            "Epoch 35/35\n",
            "263/263 [==============================] - 502s 2s/step - loss: 0.7417 - accuracy: 0.7506 - tp: 1048.0000 - fp: 1817.0000 - tn: 5269.0000 - fn: 282.0000 - precision: 0.3658 - recall: 0.7880 - auc: 0.8190 - val_loss: 0.7694 - val_accuracy: 0.7998 - val_tp: 124.0000 - val_fp: 167.0000 - val_tn: 695.0000 - val_fn: 38.0000 - val_precision: 0.4261 - val_recall: 0.7654 - val_auc: 0.8709\n",
            "Epoch 36/36\n",
            "263/263 [==============================] - 488s 2s/step - loss: 0.7371 - accuracy: 0.7590 - tp: 1061.0000 - fp: 1758.0000 - tn: 5327.0000 - fn: 270.0000 - precision: 0.3764 - recall: 0.7971 - auc: 0.8271 - val_loss: 0.7561 - val_accuracy: 0.8145 - val_tp: 105.0000 - val_fp: 134.0000 - val_tn: 729.0000 - val_fn: 56.0000 - val_precision: 0.4393 - val_recall: 0.6522 - val_auc: 0.8217\n",
            "Epoch 37/37\n",
            "263/263 [==============================] - 476s 2s/step - loss: 0.7377 - accuracy: 0.7616 - tp: 1052.0000 - fp: 1726.0000 - tn: 5358.0000 - fn: 280.0000 - precision: 0.3787 - recall: 0.7898 - auc: 0.8271 - val_loss: 0.8069 - val_accuracy: 0.7441 - val_tp: 137.0000 - val_fp: 236.0000 - val_tn: 625.0000 - val_fn: 26.0000 - val_precision: 0.3673 - val_recall: 0.8405 - val_auc: 0.8550\n",
            "Epoch 38/38\n",
            "263/263 [==============================] - 482s 2s/step - loss: 0.7361 - accuracy: 0.7747 - tp: 1030.0000 - fp: 1595.0000 - tn: 5490.0000 - fn: 301.0000 - precision: 0.3924 - recall: 0.7739 - auc: 0.8270 - val_loss: 0.7739 - val_accuracy: 0.7891 - val_tp: 122.0000 - val_fp: 176.0000 - val_tn: 686.0000 - val_fn: 40.0000 - val_precision: 0.4094 - val_recall: 0.7531 - val_auc: 0.8496\n",
            "Epoch 39/39\n",
            "263/263 [==============================] - 489s 2s/step - loss: 0.7360 - accuracy: 0.7670 - tp: 1043.0000 - fp: 1673.0000 - tn: 5412.0000 - fn: 288.0000 - precision: 0.3840 - recall: 0.7836 - auc: 0.8295 - val_loss: 0.7720 - val_accuracy: 0.7881 - val_tp: 116.0000 - val_fp: 171.0000 - val_tn: 691.0000 - val_fn: 46.0000 - val_precision: 0.4042 - val_recall: 0.7160 - val_auc: 0.8274\n",
            "Epoch 40/40\n",
            "263/263 [==============================] - 481s 2s/step - loss: 0.7362 - accuracy: 0.7637 - tp: 1050.0000 - fp: 1707.0000 - tn: 5377.0000 - fn: 282.0000 - precision: 0.3808 - recall: 0.7883 - auc: 0.8198 - val_loss: 0.8299 - val_accuracy: 0.7061 - val_tp: 140.0000 - val_fp: 279.0000 - val_tn: 583.0000 - val_fn: 22.0000 - val_precision: 0.3341 - val_recall: 0.8642 - val_auc: 0.8235\n",
            "Epoch 41/41\n",
            "263/263 [==============================] - 502s 2s/step - loss: 0.7358 - accuracy: 0.7586 - tp: 1065.0000 - fp: 1767.0000 - tn: 5319.0000 - fn: 265.0000 - precision: 0.3761 - recall: 0.8008 - auc: 0.8169 - val_loss: 0.7995 - val_accuracy: 0.7471 - val_tp: 132.0000 - val_fp: 228.0000 - val_tn: 633.0000 - val_fn: 31.0000 - val_precision: 0.3667 - val_recall: 0.8098 - val_auc: 0.8387\n",
            "Epoch 42/42\n",
            "263/263 [==============================] - 518s 2s/step - loss: 0.7363 - accuracy: 0.7590 - tp: 1057.0000 - fp: 1753.0000 - tn: 5331.0000 - fn: 275.0000 - precision: 0.3762 - recall: 0.7935 - auc: 0.8301 - val_loss: 0.7878 - val_accuracy: 0.7705 - val_tp: 124.0000 - val_fp: 196.0000 - val_tn: 665.0000 - val_fn: 39.0000 - val_precision: 0.3875 - val_recall: 0.7607 - val_auc: 0.8498\n",
            "Epoch 43/43\n",
            "263/263 [==============================] - 510s 2s/step - loss: 0.7328 - accuracy: 0.7673 - tp: 1054.0000 - fp: 1681.0000 - tn: 5404.0000 - fn: 277.0000 - precision: 0.3854 - recall: 0.7919 - auc: 0.8330 - val_loss: 0.7838 - val_accuracy: 0.7832 - val_tp: 131.0000 - val_fp: 193.0000 - val_tn: 671.0000 - val_fn: 29.0000 - val_precision: 0.4043 - val_recall: 0.8188 - val_auc: 0.8676\n",
            "Epoch 44/44\n",
            "263/263 [==============================] - 506s 2s/step - loss: 0.7350 - accuracy: 0.7755 - tp: 1033.0000 - fp: 1591.0000 - tn: 5494.0000 - fn: 298.0000 - precision: 0.3937 - recall: 0.7761 - auc: 0.8268 - val_loss: 0.7553 - val_accuracy: 0.8184 - val_tp: 113.0000 - val_fp: 137.0000 - val_tn: 725.0000 - val_fn: 49.0000 - val_precision: 0.4520 - val_recall: 0.6975 - val_auc: 0.8478\n",
            "Epoch 45/45\n",
            "263/263 [==============================] - 494s 2s/step - loss: 0.7407 - accuracy: 0.7632 - tp: 1024.0000 - fp: 1687.0000 - tn: 5399.0000 - fn: 306.0000 - precision: 0.3777 - recall: 0.7699 - auc: 0.8156 - val_loss: 0.8078 - val_accuracy: 0.7402 - val_tp: 134.0000 - val_fp: 237.0000 - val_tn: 624.0000 - val_fn: 29.0000 - val_precision: 0.3612 - val_recall: 0.8221 - val_auc: 0.8591\n",
            "Epoch 46/46\n",
            "263/263 [==============================] - 495s 2s/step - loss: 0.7331 - accuracy: 0.7773 - tp: 1046.0000 - fp: 1589.0000 - tn: 5496.0000 - fn: 285.0000 - precision: 0.3970 - recall: 0.7859 - auc: 0.8328 - val_loss: 0.7777 - val_accuracy: 0.7822 - val_tp: 121.0000 - val_fp: 181.0000 - val_tn: 680.0000 - val_fn: 42.0000 - val_precision: 0.4007 - val_recall: 0.7423 - val_auc: 0.8329\n",
            "Epoch 47/47\n",
            "263/263 [==============================] - 496s 2s/step - loss: 0.7365 - accuracy: 0.7542 - tp: 1073.0000 - fp: 1810.0000 - tn: 5274.0000 - fn: 259.0000 - precision: 0.3722 - recall: 0.8056 - auc: 0.8268 - val_loss: 0.7668 - val_accuracy: 0.7969 - val_tp: 113.0000 - val_fp: 159.0000 - val_tn: 703.0000 - val_fn: 49.0000 - val_precision: 0.4154 - val_recall: 0.6975 - val_auc: 0.8256\n",
            "Epoch 48/48\n",
            "263/263 [==============================] - 487s 2s/step - loss: 0.7396 - accuracy: 0.7494 - tp: 1054.0000 - fp: 1833.0000 - tn: 5253.0000 - fn: 276.0000 - precision: 0.3651 - recall: 0.7925 - auc: 0.8182 - val_loss: 0.7441 - val_accuracy: 0.8320 - val_tp: 102.0000 - val_fp: 115.0000 - val_tn: 750.0000 - val_fn: 57.0000 - val_precision: 0.4700 - val_recall: 0.6415 - val_auc: 0.8317\n",
            "Epoch 49/49\n",
            "263/263 [==============================] - 499s 2s/step - loss: 0.7341 - accuracy: 0.7729 - tp: 1040.0000 - fp: 1621.0000 - tn: 5465.0000 - fn: 290.0000 - precision: 0.3908 - recall: 0.7820 - auc: 0.8286 - val_loss: 0.7791 - val_accuracy: 0.7861 - val_tp: 123.0000 - val_fp: 181.0000 - val_tn: 682.0000 - val_fn: 38.0000 - val_precision: 0.4046 - val_recall: 0.7640 - val_auc: 0.8516\n",
            "Epoch 50/50\n",
            "263/263 [==============================] - 507s 2s/step - loss: 0.7357 - accuracy: 0.7678 - tp: 1043.0000 - fp: 1666.0000 - tn: 5419.0000 - fn: 288.0000 - precision: 0.3850 - recall: 0.7836 - auc: 0.8268 - val_loss: 0.7857 - val_accuracy: 0.7666 - val_tp: 124.0000 - val_fp: 200.0000 - val_tn: 661.0000 - val_fn: 39.0000 - val_precision: 0.3827 - val_recall: 0.7607 - val_auc: 0.8495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ1roKaSNU1L",
        "colab_type": "text"
      },
      "source": [
        "Fine-tuning with trainable EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXPkaFXYEctT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build model again\n",
        "\n",
        "# model = models.Sequential([\n",
        "#     hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/lite4/feature-vector/2\", trainable=True), # Trainable this time\n",
        "#     layers.Dropout(DROPOUT),\n",
        "#     layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "#     layers.Dropout(DROPOUT),\n",
        "#     layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "#     layers.Dropout(DROPOUT),\n",
        "#     layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "#     layers.Dropout(DROPOUT),\n",
        "#     layers.Dense(NEURONS_PER_LAYER, kernel_regularizer=tf.keras.regularizers.l2(REG_LAMBDA), activation=ACTIVATION),\n",
        "#     layers.Dropout(DROPOUT),\n",
        "#     layers.Dense(1, activation=\"sigmoid\")\n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), # smaller learning rate\n",
        "#     loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "#     metrics=METRICS)\n",
        "\n",
        "# model.build([None, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "# model.summary()\n",
        "\n",
        "# model.load_weights(f\"/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_4/epoch{epoch}.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKCTvoLcNYuT",
        "colab_type": "text"
      },
      "source": [
        "Train again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "and616TGNJAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train for 50 more epochs\n",
        "\n",
        "# epochsToFineTune = 150\n",
        "\n",
        "# if epoch < epochsToFineTune:\n",
        "#     for i in range(epoch, epochsToFineTune):\n",
        "#         history = model.fit(x=train_data_gen, \n",
        "#                             epochs=i+1, \n",
        "#                             initial_epoch=i, \n",
        "#                             verbose=1, \n",
        "#                             validation_data=val_data_gen, \n",
        "#                             validation_steps=VALID_LEN // batch_size, \n",
        "#                             steps_per_epoch=TRAIN_LEN // batch_size, \n",
        "#                             class_weight=class_weight,\n",
        "#                             callbacks = [csv_logger])\n",
        "#         model.save_weights(f\"/content/gdrive/My Drive/Dataset/{transferLearningCode}{NEURONS_PER_LAYER}_4/epoch{i + 1}.h5\")\n",
        "#         outfile = open(EPOCH_FILEPATH, 'wb')\n",
        "#         pickle.dump(i+1, outfile)\n",
        "#         outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}