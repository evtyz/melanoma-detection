{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "ipE0MVc9i5Yy"
      ],
      "toc_visible": true,
      "mount_file_id": "1Nfd_X2Qs4_93BSqM_xdhHvJeojFs1dlz",
      "authorship_tag": "ABX9TyPJUDklXK5XjXWPHfQHyf4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richmondvan/melanoma-detection/blob/master/process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipE0MVc9i5Yy",
        "colab_type": "text"
      },
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-qHkshQil-y",
        "colab_type": "text"
      },
      "source": [
        "**This cell is mandatory!**\n",
        "\n",
        "- Imports modules\n",
        "\n",
        "- Mounts Google Drive\n",
        "\n",
        "- Sets up constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkoVK_mvdHpM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Must be run every time!\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "from tensorflow.keras import models, layers, losses\n",
        "import math\n",
        "from google.colab import drive \n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive') \n",
        "\n",
        "DATASET_FILEPATH = \"/content/gdrive/My Drive/Dataset/dataset.zip\"\n",
        "DIRECTORY_PATH = \"/content/gdrive/My Drive/Dataset/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P5zowGv2Fx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbP1NkIb1q68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWt3c6tsiy1t",
        "colab_type": "text"
      },
      "source": [
        "One-time:\n",
        "Download my data from ISIC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvZV2S_bKpOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib\n",
        "\n",
        "urllib.request.urlretrieve(\"https://isic-archive.com/api/v1/image/download?include=all&filter={%22operator%22:%22and%22,%22operands%22:[{%22operator%22:%22in%22,%22operands%22:[{%22identifier%22:%22meta.datasetId%22,%22type%22:%22objectid%22},[%225a2ecc5e1165975c945942a4%22,%225a2ecc5e1165975c945942a2%22,%225a2ecc5d1165975c94594292%22,%225a2ecc5d1165975c9459428e%22,%225a2ecc5d1165975c94594284%22,%225aaf6f2a116597691367292e%22,%225a2ecc5d1165975c9459427e%22,%225a2ecc5d1165975c9459428a%22]]},{%22operator%22:%22and%22,%22operands%22:[{%22operator%22:%22in%22,%22operands%22:[{%22identifier%22:%22meta.clinical.benign_malignant%22,%22type%22:%22string%22},[%22benign%22,%22malignant%22]]},{%22operator%22:%22in%22,%22operands%22:[{%22identifier%22:%22meta.tags%22,%22type%22:%22string%22},[%22Challenge%202019:%20Training%22]]}]}]}\", DATASET_FILEPATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK6J7W_5jEck",
        "colab_type": "text"
      },
      "source": [
        "One-time: Extract data from archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBe07roke8JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(DATASET_FILEPATH, 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall(DIRECTORY_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAnIdjEsk0iI",
        "colab_type": "text"
      },
      "source": [
        "# More Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBGQ4BA-Svk1",
        "colab_type": "text"
      },
      "source": [
        "One-time: Converts CSV file into a dictionary for classification lookups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YCPafYCHZB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "METADATA_PATH = DIRECTORY_PATH + \"ISIC-images/metadata.csv\"\n",
        "\n",
        "with open(METADATA_PATH, mode='r') as infile:\n",
        "    reader = csv.DictReader(infile)\n",
        "    GROUND_TRUTH_DICT = {row['name'] : row['meta.clinical.benign_malignant'] for row in reader} \n",
        "\n",
        "print(GROUND_TRUTH_DICT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJT5hhYfS0Fv",
        "colab_type": "text"
      },
      "source": [
        "One-time: Sort images into proper directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVqxsRGKKhWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "IMAGE_PATH = pathlib.Path(DIRECTORY_PATH + \"ISIC-images/\")\n",
        "BENIGN_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/benign/\"\n",
        "MALIGNANT_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/malignant/\"\n",
        "\n",
        "pathlist = pathlib.Path(IMAGE_PATH).glob(\"*/*.jpg\")\n",
        "for path in pathlist:\n",
        "    fileName = path.name\n",
        "    key = GROUND_TRUTH_DICT[path.name.strip(\".jpg\")]\n",
        "    if key == \"benign\":\n",
        "        pastePath = BENIGN_PATH + path.name\n",
        "    elif key == \"malignant\":\n",
        "        pastePath = MALIGNANT_PATH + path.name\n",
        "    else:\n",
        "        print(\"error\")\n",
        "    \n",
        "    copyPath = str(path)\n",
        "\n",
        "    shutil.move(copyPath, pastePath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULJEFZ4q-AO3",
        "colab_type": "text"
      },
      "source": [
        "Sort images into training, validation, test sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjzLF-j6YGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "from random import shuffle\n",
        "\n",
        "BENIGN_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/benign/\"\n",
        "MALIGNANT_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/malignant/\"\n",
        "\n",
        "TRAINING_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/training/\"\n",
        "VALIDATION_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/validation/\"\n",
        "TEST_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/test/\"\n",
        "\n",
        "benignPathList = pathlib.Path(BENIGN_PATH).glob(\"*.jpg\")\n",
        "\n",
        "counter = 0\n",
        "for path in benignPathList:\n",
        "    name = path.name\n",
        "    copyPath = str(path)\n",
        "    counter += 1\n",
        "    key = counter % 5\n",
        "    print(key)\n",
        "    if key == 3:\n",
        "        pastePath = VALIDATION_PATH + \"benign/\" + name\n",
        "    elif key == 4:\n",
        "        pastePath = TEST_PATH + \"benign/\" + name\n",
        "    else:\n",
        "        pastePath = TRAINING_PATH + \"benign/\" + name\n",
        "    \n",
        "    shutil.move(copyPath, pastePath)\n",
        "\n",
        "malignantPathList = pathlib.Path(MALIGNANT_PATH).glob(\"*.jpg\")\n",
        "\n",
        "counter = 0\n",
        "for path in malignantPathList:\n",
        "    name = path.name\n",
        "    copyPath = str(path)\n",
        "    counter += 1\n",
        "    key = counter % 5\n",
        "    print(key)\n",
        "    if key == 3:\n",
        "        pastePath = VALIDATION_PATH + \"malignant/\" + name\n",
        "    elif key == 4:\n",
        "        pastePath = TEST_PATH + \"malignant/\" + name\n",
        "    else:\n",
        "        pastePath = TRAINING_PATH + \"malignant/\" + name\n",
        "    \n",
        "    shutil.move(copyPath, pastePath)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56UAJbSoTAJH",
        "colab_type": "text"
      },
      "source": [
        "**Mandatory!**\n",
        "\n",
        "Sets up dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WYO-ncZlFO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_label(file_path):\n",
        "    # convert the path to a list of path components\n",
        "    parts = tf.strings.split(file_path, os.path.sep)\n",
        "    # The second to last is the class-directory\n",
        "    return (parts[-2] == PRESENCE)\n",
        "\n",
        "def decode_img(img):\n",
        "    # convert the compressed string to a 3D uint8 tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # resize the image to the desired size.\n",
        "    return tf.image.resize_with_pad(img, 224, 224)\n",
        "\n",
        "def process_path(file_path):\n",
        "    label = get_label(file_path)\n",
        "\n",
        "\n",
        "    # load the raw data from the file as a string\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img, label\n",
        "\n",
        "def process_path_raw(file_path):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = decode_img(img)\n",
        "    return img\n",
        "\n",
        "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
        "    # This is a small dataset, only load it once, and keep it in memory.\n",
        "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
        "    # fit in memory.\n",
        "    \n",
        "    if cache:\n",
        "        if isinstance(cache, str):\n",
        "            ds = ds.cache(cache)\n",
        "        else:\n",
        "            ds = ds.cache()\n",
        "\n",
        "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
        "\n",
        "    # Repeat forever\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.repeat()\n",
        "\n",
        "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
        "    # is training.\n",
        "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns6qX9ULo91L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_PATH = pathlib.Path(\"/content/gdrive/My Drive/Dataset/DatasetSorted/training/\")\n",
        "VALIDATION_PATH = pathlib.Path(\"/content/gdrive/My Drive/Dataset/DatasetSorted/validation/\")\n",
        "TEST_PATH = pathlib.Path(\"/content/gdrive/My Drive/Dataset/DatasetSorted/test/\")\n",
        "\n",
        "PRESENCE = np.array([\"malignant\"])\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "TRAIN_LEN = len(list(TRAINING_PATH.glob(\"*/*.jpg\")))\n",
        "VALID_LEN = len(list(VALIDATION_PATH.glob(\"*/*.jpg\")))\n",
        "\n",
        "trainXRaw = tf.data.Dataset.list_files(str(TRAINING_PATH) + \"/*/*.jpg\")\n",
        "trainX = trainXRaw.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "trainXRaw = trainXRaw.map(process_path_raw, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "validationXRaw = tf.data.Dataset.list_files(str(VALIDATION_PATH) + \"/*/*.jpg\")\n",
        "validationX = validationXRaw.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "\n",
        "trainXRaw = prepare_for_training(trainXRaw, shuffle_buffer_size=TRAIN_LEN)\n",
        "trainX = prepare_for_training(trainX, shuffle_buffer_size=TRAIN_LEN)\n",
        "validationX = prepare_for_training(validationX, shuffle_buffer_size=VALID_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oytdCnVisftM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
        "\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                        input_shape=(224,224,3))\n",
        "\n",
        "feature_extractor_layer.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    feature_extractor_layer,\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(16),\n",
        "    layers.Dense(1)\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX5RB8gY_w92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(x=trainX, validation_data=validationX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8ZTx7FrBAc5",
        "colab_type": "text"
      },
      "source": [
        "old code do not touch, do not run\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz_P97Le-JfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "BENIGN_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/benign/\"\n",
        "MALIGNANT_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/malignant/\"\n",
        "\n",
        "TRAINING_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/training/\"\n",
        "VALIDATION_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/validation/\"\n",
        "TEST_PATH = \"/content/gdrive/My Drive/Dataset/DatasetSorted/test/\"\n",
        "\n",
        "train_image_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True) # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150\n",
        "\n",
        "CLASS_NAMES = ['benign', 'malignant']\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=TRAINING_PATH,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='binary',\n",
        "                                                           classes=CLASS_NAMES)\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=VALIDATION_PATH,\n",
        "                                                              shuffle=True,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='binary',\n",
        "                                                              classes=CLASS_NAMES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzrnYgfSSGom",
        "colab_type": "text"
      },
      "source": [
        "**Mandatory!**\n",
        "\n",
        "Prepare model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaqcRhiHSFL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with mirrored_strategy.scope():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "        layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(16, 3, padding='valid', activation='relu'),\n",
        "        layers.Conv2D(16, 3, padding='valid', activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dropout(0.1),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss=losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    for x in range(5):\n",
        "        history = model.fit(x=train_data_gen, epochs=1, verbose=1, validation_data=val_data_gen, validation_steps=1000 // batch_size, steps_per_epoch=5000 // batch_size)\n",
        "        model.save_weights('/content/gdrive/My Drive/Dataset/weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}